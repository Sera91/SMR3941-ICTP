{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaflxNZCWJc1"
      },
      "source": [
        "# Coding a Transformer from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_fSAUpAZj9E"
      },
      "source": [
        "### Cristiano De Nobili - My Contacts\n",
        "For any questions or doubts you can find my contacts here:\n",
        "\n",
        "<p align=\"center\">\n",
        "\n",
        "[<img src=\"https://img.freepik.com/premium-vector/linkedin-logo_578229-227.jpg?w=1060\" width=\"25\">](https://www.linkedin.com/in/cristiano-de-nobili/) [<img src=\"https://1.bp.blogspot.com/-Rwqcet_SHbk/T8_acMUmlmI/AAAAAAAAGgw/KD_fx__8Q4w/s1600/Twitter+bird.png\" width=\"30\">](https://twitter.com/denocris)        \n",
        "\n",
        "</p>\n",
        "\n",
        "or here (https://denocris.com).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xyzbEsEso4e"
      },
      "source": [
        "\n",
        "\n",
        "Some refs:\n",
        "\n",
        "* Original Paper: [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf);\n",
        "\n",
        "* [The Illustrated Transformer - Jay Alammar.](http://jalammar.github.io/illustrated-transformer/)\n",
        "\n",
        "\n",
        "Disclaimers:\n",
        "\n",
        "We will train in a standard way a Transformer Model. This is not BERT, which is a collection of Transformer layers. BERT is trained according to the Masked Language Model (MLM) paradigm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "7bjO3CSxXrfw"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torchtext==0.6.0 torchdata\n",
        "\n",
        "# After the installation, restart the session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "r7tW-onneT6e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "#from torchtext.legacy import data, datasets\n",
        "\n",
        "from torchtext import data, datasets\n",
        "from torchtext import vocab\n",
        "import numpy as np\n",
        "import random, tqdm, sys, math, gzip\n",
        "from torchsummary import summary\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "-fV_Q7l8USGW"
      },
      "outputs": [],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "#device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device=\"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL2RYfclXJCC",
        "outputId": "4334c3e0-27de-4557-81a3-182737e6c968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun  1 09:36:17 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P0              30W /  70W |   1241MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8AJr_0OWts0"
      },
      "source": [
        "### Multi-head Attention Mechanism, step by step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fU9jf6fW6k5"
      },
      "source": [
        "First, let's set some hyperparameters. To keep it simple we choose small size hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "mbxZtfxmW5gJ"
      },
      "outputs": [],
      "source": [
        "emb = 128 # embedding dimension (BERT like models 768)\n",
        "h = 8 # number of heads (BERT has 12 heads)\n",
        "\n",
        "batch_size = 4\n",
        "sentence_length = 21 # Context Length, 512 for BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H_vTfvzXPoy"
      },
      "source": [
        "Some fake random data with proper dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "IGxzWZhAXQCj"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(batch_size, 21, emb)\n",
        "\n",
        "b, t, e = x.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qvIpIkVYb2f",
        "outputId": "46b507e9-b5bc-4b4e-e466-8b63d4053ba9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 21, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "x.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL1idC2yYKIg"
      },
      "source": [
        "Instantiate linear transformations for query, key and values. Each transformation will act on the input vector x."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "pg5YyRrfY5b5"
      },
      "outputs": [],
      "source": [
        "tokeys    = nn.Linear(emb, emb, bias=False) # W_key\n",
        "toqueries = nn.Linear(emb, emb, bias=False) # W_query\n",
        "tovalues  = nn.Linear(emb, emb, bias=False) # W_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oUigFk1ZDNV"
      },
      "source": [
        "Generate queries, keys and values. We first compute the k/q/v's on the whole embedding vectors, and then split into the different heads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "3w9dbk45Y9k2"
      },
      "outputs": [],
      "source": [
        "keys    = tokeys(x) # W_key x\n",
        "queries = toqueries(x)\n",
        "values  = tovalues(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NItFD41X2ZqM",
        "outputId": "5aa87a71-39b5-4222-8e83-8e09f756b301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 21, 128])\n"
          ]
        }
      ],
      "source": [
        "print(keys.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfknxyThZxk3"
      },
      "source": [
        "Implement now multi-head attention (the ligther version), splitting into the different heads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgDinTEcZx-R",
        "outputId": "bb7f8bfc-60c9-46b2-9287-8a87724742f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 21, 8, 16])\n"
          ]
        }
      ],
      "source": [
        "s = e // h # 128 / 8\n",
        "\n",
        "keys    = keys.view(b, t, h, s)\n",
        "queries = queries.view(b, t, h, s)\n",
        "values  = values.view(b, t, h, s)\n",
        "\n",
        "print(keys.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIkZDhKdf9Qs",
        "outputId": "c3c7bac7-6923-404a-f1fa-0add9051d23c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 21, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "keys.transpose(1, 2).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yQO6hUrbztU",
        "outputId": "4569110d-ccda-4920-fe87-ef8606202963"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 21, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ],
      "source": [
        "keys.transpose(1, 2).contiguous().view(b * h, t, s).size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bArBBpHJdizO"
      },
      "source": [
        "We need now to compute the dot products. This is the same operation for every head, so we fold the heads into the batch dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVHJlXNWgLJc",
        "outputId": "364974fc-9d1b-4748-c54d-c63a3fd28353"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 21, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ],
      "source": [
        "keys = keys.transpose(1, 2).contiguous().view(b * h, t, s)\n",
        "queries = queries.transpose(1, 2).contiguous().view(b * h, t, s)\n",
        "values = values.transpose(1, 2).contiguous().view(b * h, t, s)\n",
        "\n",
        "# contiguous():  it actually makes a copy of the tensor such that the order of\n",
        "# its elements in memory is the same as if it had been created from scratch with the same data.\n",
        "# transpose(1, 2) doesn't generate a new tensor with a new layout, it just\n",
        "# modifies meta information in the Tensor object so that the offset and stride describe the desired new shape.\n",
        "# https://discuss.pytorch.org/t/contigious-vs-non-contigious-tensor/30107\n",
        "\n",
        "keys.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RS1sy_-e-Rd"
      },
      "source": [
        "Perform dot products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzFcqa4Sx2G4",
        "outputId": "834db8bc-e946-406a-d2e4-9336d825339a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 21, 16])\n",
            "torch.Size([32, 16, 21])\n",
            "torch.Size([32, 21, 21])\n"
          ]
        }
      ],
      "source": [
        "print(queries.size())\n",
        "\n",
        "print(keys.transpose(1, 2).size())\n",
        "\n",
        "#Let's compute the attention matrix\n",
        "attn_scores = torch.bmm(queries, keys.transpose(1, 2)).size()  # batch matrix-matrix product\n",
        "\n",
        "print(attn_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "💡 Note: `torch.bmm` and the symbol `@` are the same thing. You can check easily:\n",
        "\n",
        "```\n",
        "mat1 = torch.randn(10, 3, 4)\n",
        "mat2 = torch.randn(10, 4, 5)\n",
        "res_1 = torch.bmm(mat1, mat2)\n",
        "res_2 = mat1 @ mat2\n",
        "```\n",
        "In particular:\n",
        "* `torch.bmm`: Performs a batch matrix-matrix product of 3D tensors `mat1.size() = [b,n,m]` and `mat2.size() = [b,m,p]`, outputting `res.size() = [b,n,p]`. Here is the [documentation](https://pytorch.org/docs/stable/generated/torch.bmm.html#torch.bmm).\n",
        "* symbol `@`: The matrix multiplication(s) are done between the last two dimensions. The remaining dimensions are broadcast and batched.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YU9ReHCw2IQ5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFlUkxtLfQml"
      },
      "source": [
        "Just for completeness, below the implementation of the original multi-head attention (which is wide and computationally more intensive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkNaNkPH9eVY",
        "outputId": "de4d6784-ca1c-4f46-d619-331b4e3bb842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 21, 1024])\n",
            "torch.Size([4, 21, 8, 128])\n"
          ]
        }
      ],
      "source": [
        "emb = 128\n",
        "h = 8\n",
        "\n",
        "x = torch.rand(4, 21, emb)\n",
        "\n",
        "b, t, e = x.size()\n",
        "\n",
        "tokeys    = nn.Linear(emb, emb * h, bias=False)\n",
        "toqueries = nn.Linear(emb, emb * h, bias=False)\n",
        "tovalues  = nn.Linear(emb, emb * h, bias=False)\n",
        "\n",
        "keys    = tokeys(x)\n",
        "queries = toqueries(x)\n",
        "values  = tovalues(x)\n",
        "\n",
        "print(keys.size())\n",
        "\n",
        "keys    = keys.view(b, t, h, e)\n",
        "queries = queries.view(b, t, h, e)\n",
        "values  = values.view(b, t, h, e)\n",
        "\n",
        "print(keys.size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DC9fbHbnzhP"
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPaxkMJaffkh"
      },
      "source": [
        "Let us collect everything and define the self-attention class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "NrvYJ5tPYI7L"
      },
      "outputs": [],
      "source": [
        "class MHSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head self attention.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, emb, heads=8):\n",
        "        \"\"\"\n",
        "        :param emb:\n",
        "        :param heads:\n",
        "        :param mask:\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        assert emb % heads == 0, f'Embedding dimension ({emb}) should be divisible by nr. of heads ({heads})'\n",
        "\n",
        "        self.emb = emb\n",
        "        self.heads = heads\n",
        "\n",
        "        #s = emb // heads\n",
        "        # - We will break the embedding into `heads` chunks and feed each to a different attention head\n",
        "\n",
        "        self.tokeys    = nn.Linear(emb, emb, bias=False) # W_key\n",
        "        self.toqueries = nn.Linear(emb, emb, bias=False) # W_query\n",
        "        self.tovalues  = nn.Linear(emb, emb, bias=False) # W_value\n",
        "\n",
        "        self.unifyheads = nn.Linear(emb, emb)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        b, t, e = x.size()\n",
        "        h = self.heads\n",
        "        assert e == self.emb, f'Input embedding dim ({e}) should match layer embedding dim ({self.emb})'\n",
        "\n",
        "        s = e // h\n",
        "\n",
        "        # We first compute the k/q/v's on the whole embedding vectors, and then split into the different heads.\n",
        "\n",
        "        keys    = self.tokeys(x)\n",
        "        queries = self.toqueries(x)\n",
        "        values  = self.tovalues(x)\n",
        "\n",
        "        # Split into the different heads.\n",
        "\n",
        "        keys    = keys.view(b, t, h, s)\n",
        "        queries = queries.view(b, t, h, s)\n",
        "        values  = values.view(b, t, h, s)\n",
        "\n",
        "        # Compute scaled dot-product self-attention\n",
        "\n",
        "        # Fold heads into the batch dimension\n",
        "        # When you call contiguous(), it actually makes a copy of the tensor\n",
        "        # such that the order of its elements in memory is the same as if it had been created from scratch with the same data.\n",
        "        keys = keys.transpose(1, 2).contiguous().view(b * h, t, s)\n",
        "        queries = queries.transpose(1, 2).contiguous().view(b * h, t, s)\n",
        "        values = values.transpose(1, 2).contiguous().view(b * h, t, s)\n",
        "\n",
        "        queries = queries / (e ** (1/4))\n",
        "        keys    = keys / (e ** (1/4))\n",
        "        # Instead of dividing the dot products by sqrt(e), we scale the keys and values.\n",
        "        # This should be more memory efficient\n",
        "\n",
        "        # Get dot product of queries and keys, and scale.\n",
        "\n",
        "        attn_scores = torch.bmm(queries, keys.transpose(1, 2))\n",
        "\n",
        "        assert attn_scores.size() == (b * h, t, t)\n",
        "\n",
        "        attn_weights = F.softmax(attn_scores, dim=2) # Dot now has row-wise self-attention probabilities\n",
        "\n",
        "        # apply the self attention to the values\n",
        "        out = torch.bmm(attn_weights, values).view(b, h, t, s)\n",
        "\n",
        "        # swap h, t back, unify heads\n",
        "        out = out.transpose(1, 2).contiguous().view(b, t, s * h)\n",
        "\n",
        "        return self.unifyheads(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIVMd_jgoTUG"
      },
      "source": [
        "A Transformer Block is based on self-attention (and Layer Normalization, Residual Connections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "edyQsYXSOe7j"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, emb, heads, mask, seq_length, ff_hidden_mult=4, dropout=0.0, pos_embedding=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mhattention = MHSelfAttention(emb, heads=heads)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(emb)\n",
        "        self.norm2 = nn.LayerNorm(emb)\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(emb, ff_hidden_mult * emb),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_hidden_mult * emb, emb)\n",
        "        )\n",
        "\n",
        "        self.do = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        attended = self.mhattention(x)\n",
        "\n",
        "        x = self.norm1(attended + x) #residual\n",
        "\n",
        "        x = self.do(x)\n",
        "\n",
        "        fedforward = self.ff(x)\n",
        "\n",
        "        x = self.norm2(fedforward + x) #residual\n",
        "\n",
        "        x = self.do(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLkJs-d1oo4o"
      },
      "source": [
        "Let's build a Transformers (a stack of Transformers Blocks) and adapt it for a binary classification task. Its `depth` defines the number of Transformers Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "mOEjyiOKGyYO"
      },
      "outputs": [],
      "source": [
        "class CTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self, emb, heads, depth, seq_length, num_tokens, num_classes, max_pool=True, dropout=0.0):\n",
        "        \"\"\"\n",
        "        :param emb: Embedding dimension\n",
        "        :param heads: nr. of attention heads\n",
        "        :param depth: Number of transformer blocks\n",
        "        :param seq_length: Expected maximum sequence length\n",
        "        :param num_tokens: Number of tokens (usually words) in the vocabulary\n",
        "        :param num_classes: Number of classes.\n",
        "        :param max_pool: If true, use global max pooling in the last layer. If false, use global\n",
        "                         average pooling.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_tokens, self.max_pool = num_tokens, max_pool\n",
        "\n",
        "        # Token embedding\n",
        "        self.token_embedding = nn.Embedding(embedding_dim=emb, num_embeddings=num_tokens)\n",
        "        # Position embedding\n",
        "        self.pos_embedding = nn.Embedding(embedding_dim=emb, num_embeddings=seq_length)\n",
        "\n",
        "        tblocks = []\n",
        "        for i in range(depth):\n",
        "            tblocks.append(\n",
        "                TransformerBlock(emb=emb, heads=heads, seq_length=seq_length, mask=False, dropout=dropout))\n",
        "\n",
        "        self.tblocks = nn.Sequential(*tblocks)\n",
        "\n",
        "        self.toprobs = nn.Linear(emb, num_classes)\n",
        "\n",
        "        self.do = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: A batch by sequence length integer tensor of token indices.\n",
        "        :return: predicted log-probability vectors for each token based on the preceding tokens.\n",
        "        \"\"\"\n",
        "        tokens = self.token_embedding(x)\n",
        "        b, t, e = tokens.size()\n",
        "\n",
        "        positions = self.pos_embedding(torch.arange(t, device=device))[None, :, :].expand(b, t, e)\n",
        "        x = tokens + positions\n",
        "        x = self.do(x)\n",
        "\n",
        "        x = self.tblocks(x)\n",
        "\n",
        "        x = x.max(dim=1)[0] if self.max_pool else x.mean(dim=1) # pool over the time dimension\n",
        "\n",
        "        x = self.toprobs(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1) # nn.softmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAt7m7h-1jxH",
        "outputId": "901482a1-e8ce-4523-c701-d541d36a3d66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "        18, 19, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ],
      "source": [
        "torch.arange(21)\n",
        "# [0, 0, ..., 0]\n",
        "# [1, 1, ..., 1]\n",
        "# ...\n",
        "# [20, 20, ..., 20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLHykvt51B9Q"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUq9RpF-1M1L"
      },
      "source": [
        "One of the main concepts of TorchText is the `Field`. These define how your data should be processed. In our sentiment classification task the data consists of both the raw string of the review and the sentiment, either \"pos\" or \"neg\".\n",
        "\n",
        "The parameters of a `Field` specify how the data should be processed.\n",
        "\n",
        "We use the `TEXT` field to define how the review should be processed, and the `LABEL` field to process the sentiment.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def get_IMDB_from_torchtext():\n",
        "    SEED=42\n",
        "    VOC_SIZE = 50000\n",
        "    BATCH_SIZE = 4\n",
        "    TEXT = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
        "    LABEL = data.LabelField(sequential=False, dtype = torch.float, batch_first=True)\n",
        "    train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
        "    #TEXT.build_vocab(train, max_size=VOC_SIZE - 2)\n",
        "    #LABEL.build_vocab(train)\n",
        "    #train_iter, test_iter = data.Iterator.splits((train, test), batch_size=1, device = 'cpu')\n",
        "    #train_iter, test_iter  = data.BucketIterator.splits((train, test), batch_size=BATCH_SIZE, device='cpu')\n",
        "    #train_iter, valid_iter = train_iter.split(random_state = random.seed(SEED), split_ratio=0.8)\n",
        "\n",
        "    labels, reviews = [], []\n",
        "    for line in train.examples:\n",
        "        #print(item.label, item.text )\n",
        "        label=vars(line)['label']\n",
        "        review=''.join(str(var)+\" \" for var in vars(line)['text'])\n",
        "        assert label in ('pos', 'neg')\n",
        "        #print(label)\n",
        "        labels.append(label)\n",
        "        reviews.append(review)\n",
        "    df_train = pd.DataFrame({'sentiment': labels, 'review': reviews})\n",
        "    df_train['sentiment'] = df_train['sentiment'].map({'pos': 1, 'neg': 0})\n",
        "    print('original df_train.shape: ', df_train.shape)\n",
        "    #df_train = df_train.drop_duplicates()\n",
        "    #print('after drop_duplicates, df_train.shape: ', df_train.shape)\n",
        "    labels, reviews = [], []\n",
        "    for line in test.examples:\n",
        "        label=vars(line)['label']\n",
        "        review=vars(line)['text']\n",
        "        assert label in ('pos', 'neg')\n",
        "        labels.append(label)\n",
        "        reviews.append(review)\n",
        "    df_test = pd.DataFrame({'sentiment': labels, 'review': reviews})\n",
        "    df_test['sentiment'] = df_test['sentiment'].map({'pos': 1, 'neg': 0})\n",
        "    print('original df_test.shape: ', df_test.shape)\n",
        "    #df_test = df_test.drop_duplicates()\n",
        "    #print('after drop_duplicates, df_test.shape: ', df_test.shape)\n",
        "\n",
        "    return df_train, df_test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_train, df_test = get_IMDB_from_torchtext()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV923LZnt8E4",
        "outputId": "ee30508a-81be-43e2-c4e0-97f33ab9f5fe"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original df_train.shape:  (25000, 2)\n",
            "original df_test.shape:  (25000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_train.to_csv('./imdb_train.csv', index=True)\n",
        "df_test.to_csv('./imdb_test.csv', index=True)"
      ],
      "metadata": {
        "id": "xuKPTMChviY4"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NB0C01PY_2KE",
        "outputId": "a8f66fce-f5f0-487e-fc62-d8c115feb7ab"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sentiment                                             review\n",
              "0          1  the movie held my interest, mainly because dia...\n",
              "1          1  the sopranos (1999-2007)<br /><br />number 1 -...\n",
              "2          1  one of the funnest mario's i've ever played. t...\n",
              "3          1  i was lucky enough to get a dvd copy of this m...\n",
              "4          1  a frolics of youth short subject.<br /><br />a..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc15fb30-8930-4242-9466-559371c3e3fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>the movie held my interest, mainly because dia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the sopranos (1999-2007)&lt;br /&gt;&lt;br /&gt;number 1 -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>one of the funnest mario's i've ever played. t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>i was lucky enough to get a dvd copy of this m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>a frolics of youth short subject.&lt;br /&gt;&lt;br /&gt;a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc15fb30-8930-4242-9466-559371c3e3fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc15fb30-8930-4242-9466-559371c3e3fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc15fb30-8930-4242-9466-559371c3e3fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e7cdc88b-60d1-4474-8e6b-69c7505315a5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e7cdc88b-60d1-4474-8e6b-69c7505315a5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e7cdc88b-60d1-4474-8e6b-69c7505315a5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 25000,\n  \"fields\": [\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24904,\n        \"samples\": [\n          \"this is the first guinea pig film from japan and this is the sickest, in my opinion. a bunch of guys torture a girl for several days before finally killing her. and at this point, i will say that these films are not real! they are faked horror films which try to be as realistic as possible.<br /><br />the scenes are sickening but also unrealistic in many cases. for example, when they kick the girl in the floor, we can clearly see how they kick and stump the floor near the girl! and how stupid this looks! the sound effects are also unrealistic and don't make sense. other scenes include animal intestines thrown on the girl, the girl exposed to loud noises for many hours, the ripping off of fingernails, worms placed on the wounds in the girl's body, the eye pierced and mutilated in horrific detail and stuff like that. very sick and mean spirited film and has absolutely nothing valuable or cinematically significant. this first entry is the sickest and most amateurish guinea pig, although it is not as bloody as the next part, flowers of flesh and blood, which tries to be as shocking as possible.<br /><br />guinea pig: devil's experiment is perhaps the sickest thing i've seen and the closest thing to snuff there is. this is still (of course) faked s(n/t)uff, the only difference to genuine \\\"snuff film\\\" is that no one dies or hurts for real in this film. i cannot recommend this to anyone since thi s is so s****y and repulsive. they who consider this is a great horror film understand nothing about cinema and the real meaning of it. i watched this as a curiosity (as the other parts in the series) and now i know how insignificant trash these are. they work only in shock level and that's not too valuable cinematic achievement. devil's experiment is perhaps the sickest film i've seen and mermaid in a manhole (guinea pig 4) is perhaps the most disgusting film i've seen. so these are pretty extreme in my book, but that's all they are. \",\n          \"to anyone who might think this show isn't for them, please give it a try. network television has degenerated into shows that are clones of clones or are reality based shows featuring some often unreal people. this show is a return to family oriented tv where the emphasis is on learning some life lessons, learning what real friends and family are about, and maybe even learning a little bit about our national pastime. jeremy sumpter is one of the most appealing young actors in show business today, and he is perfectly cast as the young, slightly naive new batboy for the fictional new york empires (great name!). dean cain, christopher lloyd, mare winningham, and kirsten storms round out the main cast, and they are all exceptional. this show deserves a chance to catch on and be seen. hopefully it will stick around for a few seasons and we can watch pete young (sumpter's character) learn and grow. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(train_data[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErSwgqhgAwyf",
        "outputId": "949f150b-1179-486e-ddd4-f489cf6dfbe2"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sentiment': '1', 'review': ['the', 'movie', 'held', 'my', 'interest,', 'mainly', 'because', 'dianne', 'keaton', 'is', 'my', 'favorite', 'actress.', 'i', 'disagree', 'with', 'some', 'of', 'the', 'other', 'posts', 'on', 'the', 'grounds', 'that', 'the', 'plot', 'was', 'not', 'convoluted.', 'i', 'had', 'no', 'trouble', 'following', 'it', '(maybe', 'some', 'people', 'had', 'too', 'much', 'eggnog', 'the', 'night', 'before).', 'the', 'movie', 'was', 'very', 'sad', 'and', 'touching', 'as', 'well.', 'what', 'more', 'do', 'you', 'want?', 'alexa', 'davalos', 'is', 'a', 'fine', 'new', 'talent', '(beautiful', 'too),', 'and', 'tom', 'everett', 'scott', 'does', 'an', 'excellent', 'job', 'with', 'his', 'part', 'as', 'well.', 'the', 'relationship', 'of', 'the', 'mother', 'and', 'daughter', 'may', 'have', 'been', 'a', 'bit', 'unrealistic,', 'but', 'the', 'behavior', 'of', 'the', 'young', 'people', 'in', 'the', 'movie', 'was', 'not.', 'it', 'was', 'tragically', 'sad', 'but', 'enlightening.', 'it', 'sure', 'beat', 'the', 'other', 'shows', 'that', 'were', 'on', 'tv', 'new', 'years', 'day', 'evening']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "PwZCH0cdNNld"
      },
      "outputs": [],
      "source": [
        "TEXT=data.Field(batch_first=True) # If no tokenize argument is passed, the default is simply splitting the string on spaces.\n",
        "LABEL=data.LabelField(sequential=False, dtype = torch.float, batch_first=True,use_vocab=False)\n",
        "\n",
        "NUM_CLS = 2\n",
        "BATCH_SIZE = 4\n",
        "MAX_LENGTH = 256 #512\n",
        "EMB_SIZE = 128\n",
        "HEADS = 8\n",
        "DEPTH = 3 #Number of self-attention layer\n",
        "VOC_SIZE = 50000\n",
        "\n",
        "LR_RATE = 0.0001\n",
        "WARMUP = 10000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fields = [(None, None),('sentiment',LABEL),('review',TEXT)]\n",
        "\n",
        "train_data, test_data = data.TabularDataset.splits(\n",
        "                                        path = './',\n",
        "                                        train = 'imdb_train.csv',\n",
        "                                        test = 'imdb_test.csv',\n",
        "                                        format = 'csv',\n",
        "                                        fields = fields,\n",
        "                                        skip_header = True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "xz5NmltIvuOO"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "Q1MIFNoQXyJO"
      },
      "outputs": [],
      "source": [
        "#tbw = SummaryWriter(log_dir='./logs') # Tensorboard logging\n",
        "\n",
        "#train, test = datasets.IMDB.splits(TEXT, LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "M67EEOAjO6Yw"
      },
      "outputs": [],
      "source": [
        "#TEXT = data.Field(tokenize='spacy', batch_first=True)\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = VOC_SIZE-2)\n",
        "LABEL.build_vocab(train_data)\n",
        "#TEXT.build_vocab(train, max_size=VOC_SIZE - 2)\n",
        "#LABEL.build_vocab(train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGtjHiEZ4u4S",
        "outputId": "5a627789-ff2f-4739-9562-cf13b7e6232a"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 322198),\n",
              " ('a', 159953),\n",
              " ('and', 158572),\n",
              " ('of', 144462),\n",
              " ('to', 133967),\n",
              " ('is', 104171),\n",
              " ('in', 90527),\n",
              " ('i', 70480),\n",
              " ('this', 69714),\n",
              " ('that', 66292)]"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device='cpu'\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "train_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, test_data),\n",
        "    sort_key = lambda x: x.sentiment, #sort by s attribute (sentiment)\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)"
      ],
      "metadata": {
        "id": "Tnu4DIK4Gqxb"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nddhgBgyfGo",
        "outputId": "116f4f73-eb4b-461d-e9ee-4cca54286a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch.sentiment.size:\n",
            "torch.Size([4])\n",
            "batch.review:\n",
            "torch.Size([4, 570])\n"
          ]
        }
      ],
      "source": [
        "# batch size = 4\n",
        "for batch in train_iter:\n",
        "    print(\"batch.sentiment.size:\")\n",
        "    print(batch.sentiment.size())\n",
        "    print(\"batch.review:\")\n",
        "    print(batch.review.size())\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLvUJVGgSYu9",
        "outputId": "33fbdcff-e507-491c-d06a-9243057eaaf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- nr. of training examples 6250\n",
            "- nr. of test examples 6250\n"
          ]
        }
      ],
      "source": [
        "print(f'- nr. of training examples {len(train_iter)}')\n",
        "print(f'- nr. of test examples {len(test_iter)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMi5jQ5fV8l7",
        "outputId": "80aa65e8-2faf-4188-e4a9-f6c76cd00346"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CTransformer(\n",
              "  (token_embedding): Embedding(50000, 128)\n",
              "  (pos_embedding): Embedding(256, 128)\n",
              "  (tblocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (mhattention): MHSelfAttention(\n",
              "        (tokeys): Linear(in_features=128, out_features=128, bias=False)\n",
              "        (toqueries): Linear(in_features=128, out_features=128, bias=False)\n",
              "        (tovalues): Linear(in_features=128, out_features=128, bias=False)\n",
              "        (unifyheads): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "      )\n",
              "      (do): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (mhattention): MHSelfAttention(\n",
              "        (tokeys): Linear(in_features=128, out_features=128, bias=False)\n",
              "        (toqueries): Linear(in_features=128, out_features=128, bias=False)\n",
              "        (tovalues): Linear(in_features=128, out_features=128, bias=False)\n",
              "        (unifyheads): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "      )\n",
              "      (do): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (mhattention): MHSelfAttention(\n",
              "        (tokeys): Linear(in_features=128, out_features=128, bias=False)\n",
              "        (toqueries): Linear(in_features=128, out_features=128, bias=False)\n",
              "        (tovalues): Linear(in_features=128, out_features=128, bias=False)\n",
              "        (unifyheads): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "      )\n",
              "      (do): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (toprobs): Linear(in_features=128, out_features=2, bias=True)\n",
              "  (do): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "# create the model\n",
        "model = CTransformer(emb=EMB_SIZE, heads=HEADS, depth=DEPTH, seq_length=MAX_LENGTH, num_tokens=VOC_SIZE, num_classes=NUM_CLS, max_pool=\"store_true\", dropout=0.2)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "MNIoieCfcbpa"
      },
      "outputs": [],
      "source": [
        "opt = torch.optim.Adam(lr=LR_RATE, params=model.parameters())\n",
        "sch = torch.optim.lr_scheduler.LambdaLR(opt, lambda i: min(i / (WARMUP / BATCH_SIZE), 1.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2WjYN9If758",
        "outputId": "d045e3cd-78a7-49fb-e442-627be4d1af54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 5071/6250 [07:25<01:46, 11.04it/s]"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 4\n",
        "\n",
        "# training loop\n",
        "seen = 0\n",
        "for e in range(NUM_EPOCHS):\n",
        "\n",
        "    print(f'\\n epoch {e}')\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm.tqdm(train_iter):\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        input = batch.review\n",
        "        input = input.to(device)\n",
        "        label = batch.sentiment.to(torch.long)\n",
        "        label = label.to(device)\n",
        "\n",
        "        if input.size(1) > MAX_LENGTH:\n",
        "            input = input[:, :MAX_LENGTH]\n",
        "\n",
        "\n",
        "        out = model(input)\n",
        "        loss = F.nll_loss(out, label)\n",
        "        # loss = CrossEntropy(out, label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # clip gradients\n",
        "        # Performs gradient clipping. It is used to mitigate the problem of exploding gradients.\n",
        "        # - If the total gradient vector has a length > 1, we clip it back down to 1.\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        opt.step()\n",
        "        sch.step()\n",
        "\n",
        "        seen += input.size(0)\n",
        "        tbw.add_scalar('classification/train-loss', float(loss.item()), seen)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        model.eval()\n",
        "        tot, cor= 0.0, 0.0\n",
        "\n",
        "        for batch in test_iter:\n",
        "\n",
        "            input = batch.review\n",
        "            input = input.to(device)\n",
        "            label = batch.sentiment.to(torch.long)\n",
        "            label = label.to(device)\n",
        "            if input.size(1) > MAX_LENGTH:\n",
        "                input = input[:, :MAX_LENGTH]\n",
        "            out = model(input).argmax(dim=1)\n",
        "\n",
        "            tot += float(input.size(0))\n",
        "            cor += float((label == out).sum().item())\n",
        "\n",
        "        acc = cor / tot\n",
        "        print(f'-- test accuracy {acc:.3}')\n",
        "        tbw.add_scalar('classification/test-loss', float(loss.item()), e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wr1VbzzEn-PH"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "\n",
        "\n",
        "model_inference = model.load_weigths('path')\n",
        "\n",
        "model_inference(\"I bought that book and I enjoyed the readings\")\n",
        "\n",
        "# 0 o 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}